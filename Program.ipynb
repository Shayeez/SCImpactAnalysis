{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the number of selected features for RFE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def corfeatures(data):\n",
    "    correlated_features = set()\n",
    "    correlation_matrix = data.drop(['Profit'], axis = 1 ).corr()\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(correlation_matrix.iloc[i,j]) > 0.95:\n",
    "                colname = correlation_matrix.columns[i]\n",
    "                correlated_features.add(colname)\n",
    "    #print(\"Correlated Features :\\n\", correlated_features)\n",
    "    newdata = data.drop(list(correlated_features), axis = 1)\n",
    "    #print()\n",
    "    #print(\"Shape of dataset after elimination correlated features: \", newdata.shape)\n",
    "    #print()\n",
    "    return newdata\n",
    "\n",
    "def sol(l, X, y):\n",
    "    rfecv = RFECV(estimator=l, step=1, cv=RepeatedKFold(10), scoring='r2')\n",
    "    rfecv.fit(X, y)\n",
    "    #print(\"Optimal No. of Features: \", rfecv.n_features_)\n",
    "    f = rfecv.get_support(1) #the most important features\n",
    "    #print(X.columns[f])\n",
    "    #print()\n",
    "    #print(rfecv.grid_scores_)\n",
    "    return X\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def corfeatures1(data,test):\n",
    "    correlated_features = set()\n",
    "    correlation_matrix = data.drop(['Profit'], axis = 1 ).corr()\n",
    "    for i in range(len(correlation_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(correlation_matrix.iloc[i,j]) > 0.95:\n",
    "                colname = correlation_matrix.columns[i]\n",
    "                correlated_features.add(colname)\n",
    "    #print(\"Correlated Features :\\n\", correlated_features)\n",
    "    newdata = data.drop(list(correlated_features), axis = 1)\n",
    "    newtest = test.drop(list(correlated_features), axis = 1)\n",
    "    #print()\n",
    "    #print(\"Shape of dataset after elimination correlated features: \", newdata.shape)\n",
    "    #print()\n",
    "    return newdata, newtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split provided dataset into train & test dataset\n",
    "\n",
    "data = pd.read_excel(\"ml_demand-2.xlsx\")\n",
    "\n",
    "newdata = corfeatures(data)\n",
    "\n",
    "x = newdata.drop(['Profit'], axis = 1)\n",
    "y = newdata['Profit'].copy()\n",
    "\n",
    "reg = [LinearRegression(), DecisionTreeRegressor(), RandomForestRegressor()]\n",
    "\n",
    "for i in reg:\n",
    "    print()\n",
    "    print(i)\n",
    "    x_new = sol(i, x, y)\n",
    "    print()\n",
    "    \n",
    "    #Spliiting Data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x_new, y, test_size=0.25)\n",
    "    \n",
    "    d = i\n",
    "    d.fit(x_train, y_train)\n",
    "    predictions = d.predict(x_test)\n",
    "    print(r2_score(y_test, predictions))\n",
    "    print(mean_absolute_error(y_test, predictions))\n",
    "    print(mean_squared_error(y_test, predictions))\n",
    "    print(\"-------------------------------------------------------------------------------------------------------------\")\n",
    "    print()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperate dataset for train & test\n",
    "\n",
    "#Read train and test dataset\n",
    "data=pd.read_excel(\"full.xlsx\")\n",
    "trnst = pd.read_excel(\"disruptns.xlsx\")\n",
    "\n",
    "#Removing correlated features\n",
    "newdata, test = corfeatures1(data, trnst)\n",
    "\n",
    "#define x & y for train\n",
    "x = newdata.drop(['Profit'], axis = 1 )\n",
    "y = newdata['Profit'].copy()\n",
    "\n",
    "#define x & y for test\n",
    "test_x = test.drop(['Profit'], axis = 1)\n",
    "test_y = test['Profit'].copy()\n",
    "\n",
    "reg = [LinearRegression(), DecisionTreeRegressor(), RandomForestRegressor()]\n",
    "\n",
    "for i in reg:\n",
    "    print()\n",
    "    print(i)\n",
    "    x_new = sol(i, x, y)\n",
    "    print()\n",
    "    \n",
    "    d = i\n",
    "    d.fit(x_new, y)\n",
    "    predictions = d.predict(test_x)\n",
    "    print(r2_score(test_y, predictions))\n",
    "    print(mean_absolute_error(test_y, predictions))\n",
    "    print(mean_squared_error(test_y, predictions))\n",
    "    print(\"-------------------------------------------------------------------------------------------------------------\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deep Neural Network Regression\n",
    "\n",
    "#Reading data\n",
    "data=pd.read_excel(\"full.xlsx\")\n",
    "trnst = pd.read_excel(\"disruptns.xlsx\")\n",
    "\n",
    "#Removing correlated features\n",
    "newdata, test = corfeatures1(data, trnst)\n",
    "\n",
    "#define x & y for train\n",
    "x = newdata.drop(['Profit'], axis = 1 )\n",
    "y = newdata['Profit'].copy()\n",
    "\n",
    "#define x & y for test\n",
    "test_x = test.drop(['Profit'], axis = 1)\n",
    "test_y = test['Profit'].copy()\n",
    "\n",
    "NN_model = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = x.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.summary()\n",
    "\n",
    "checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "#Fitting the model\n",
    "NN_model.fit(x, y, epochs=500, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)\n",
    "\n",
    "predictions = NN_model.predict(test_x)\n",
    "print(r2_score(test_y, predictions))\n",
    "print(mean_absolute_error(test_y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)\n",
      "\n",
      "[-24861.17902099  47059.82521258]\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
      "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      presort=False, random_state=None, splitter='best')\n",
      "\n",
      "[-22510.          49727.00319645]\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
      "                      max_features='auto', max_leaf_nodes=None,\n",
      "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                      min_samples_leaf=1, min_samples_split=2,\n",
      "                      min_weight_fraction_leaf=0.0, n_estimators='warn',\n",
      "                      n_jobs=None, oob_score=False, random_state=None,\n",
      "                      verbose=0, warm_start=False)\n",
      "\n",
      "[-22510.          49727.00319645]\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print predictions\n",
    "\n",
    "#Read train and test dataset\n",
    "data=pd.read_excel(\"full.xlsx\")\n",
    "trnst = pd.read_excel(\"progrm.xlsx\")\n",
    "\n",
    "#Removing correlated features\n",
    "newdata, test = corfeatures1(data, trnst)\n",
    "\n",
    "#define x & y for train\n",
    "x = newdata.drop(['Profit'], axis = 1 )\n",
    "y = newdata['Profit'].copy()\n",
    "\n",
    "#define x & y for test\n",
    "test_x = test\n",
    "#test_y = test['Profit'].copy()\n",
    "\n",
    "\n",
    "reg = [LinearRegression(), DecisionTreeRegressor(), RandomForestRegressor()]\n",
    "\n",
    "for i in reg:\n",
    "    print()\n",
    "    print(i)\n",
    "    x_new = sol(i, x, y)\n",
    "    print()\n",
    "    \n",
    "    d = i\n",
    "    d.fit(x_new, y)\n",
    "    predictions = d.predict(test_x)\n",
    "    print(predictions)\n",
    "    #print(r2_score(test_y, predictions))\n",
    "    #print(mean_absolute_error(test_y, predictions))\n",
    "    #print(mean_squared_error(test_y, predictions))\n",
    "    print(\"-------------------------------------------------------------------------------------------------------------\")\n",
    "    print()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
